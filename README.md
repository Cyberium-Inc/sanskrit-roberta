As of 16th April 2024, we have achieved 0.3% accuracy(training loss) in the Roberta tokenizer with BPE vocab.
![image](https://github.com/Cyberium-Inc/sanskrit-roberta/assets/38162857/27a2a92e-3873-435d-abac-68817e7df96a)
